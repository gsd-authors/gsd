{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T17:18:18.496394Z",
     "start_time": "2023-12-17T17:18:18.467824Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import gsd\n",
    "import gsd.experimental as gsde\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import requests\n",
    "import tensorflow_probability.substrates.jax as tfp\n",
    "from gsd.experimental.bootstrap import pp_plot_data\n",
    "from gsd.experimental.fit import GridEstimator\n",
    "from gsd.fit import GSDParams, allowed_region, make_logits\n",
    "from jax import Array\n",
    "from jax.flatten_util import ravel_pytree\n",
    "from jax.typing import ArrayLike\n",
    "\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7b4d0c27bc1fba",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Lets use one experiment form sureal library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd38f4150b3992c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T17:18:18.778139Z",
     "start_time": "2023-12-17T17:18:18.472132Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/Netflix/sureal/master/test/resource/NFLX_dataset_public_raw.py\"  \n",
    "dataset = {}\n",
    "try:\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        content = response.text\n",
    "        exec(content, {}, dataset)\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the file. Status code: {response.status_code}\")\n",
    "except requests.RequestException as e:\n",
    "    print(f\"Error fetching the file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a657c1880da152",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T17:18:18.784810Z",
     "start_time": "2023-12-17T17:18:18.780033Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "o = np.asarray([v[\"os\"] for v in dataset[\"dis_videos\"]])\n",
    "print(o.shape)\n",
    "counts = jax.vmap(gsd.sufficient_statistic)(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1f98a58a65ad26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T17:18:18.786284Z",
     "start_time": "2023-12-17T17:18:18.784527Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hdtv = False\n",
    "#hdtv = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf4379062357bf3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T17:18:18.791755Z",
     "start_time": "2023-12-17T17:18:18.787797Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "if hdtv:\n",
    "    hdtv = pd.read_csv(\n",
    "        \"/Users/krzysiek/Documents/lts_analysis_soft/pyits/log/hdtv_data.csv\"\n",
    "    )\n",
    "    exp1 = hdtv[hdtv.Experiment == 1]\n",
    "    exp1\n",
    "    n_sub = 24\n",
    "    n_pvs = 168\n",
    "    o = np.zeros((n_pvs, n_sub))\n",
    "    o = pd.pivot(exp1, columns=\"Tester_id\", values=\"Score\", index=\"PVS_id\").to_numpy()\n",
    " \n",
    "    counts = jax.vmap(gsd.sufficient_statistic)(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6704abfdd927c4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T17:18:18.797626Z",
     "start_time": "2023-12-17T17:18:18.792202Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def gsdfit(x: Array):\n",
    "    params, opt_state = gsde.fit_mle(data=x, max_iterations=200)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f03ac8756106f5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Fit model for a single PVS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd385dbacc3274db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T17:18:19.116794Z",
     "start_time": "2023-12-17T17:18:18.794291Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gsdfit(counts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c131353afb7ec48",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "And compare the fit to the one estimated without a gradient:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d429f5393afe2ad3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T17:18:19.128697Z",
     "start_time": "2023-12-17T17:18:19.127249Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta0 = GSDParams(psi=2.0, rho=0.9)\n",
    "x0, unravel_fn = ravel_pytree(theta0)\n",
    "\n",
    "\n",
    "def nll(x: ArrayLike, data: Array) -> Array:\n",
    "    logits = make_logits(unravel_fn(x))\n",
    "    #tv = allowed_region(logits, data.sum())\n",
    "    ret = -jnp.dot(logits, data)\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def tfpfit(data: Array):\n",
    "    initial_simplex = np.asarray(\n",
    "        [\n",
    "            [4.9, 0.1],\n",
    "            [1.1, 0.9],\n",
    "            [4.9, 0.9],\n",
    "        ]\n",
    "    )\n",
    "    results = tfp.optimizer.nelder_mead_minimize(\n",
    "        partial(nll, data=data), initial_simplex=jnp.asarray(initial_simplex)\n",
    "    )\n",
    "    return unravel_fn(results.position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635036841f94975e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T17:19:18.006833Z",
     "start_time": "2023-12-17T17:19:17.998934Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[gsdfit(counts[0]), tfpfit(counts[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b58d36e594762c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let's estimate parameter for all the PVSs. \n",
    "For this we are going to use `jax.lax.map`.\n",
    " _Note, that `vmap` is nor best here as each estimatio contain control flow instructions._\n",
    "  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53e0644aadfcb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T17:18:21.598047Z",
     "start_time": "2023-12-17T17:18:21.259299Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fits = jax.lax.map(gsdfit, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97a3617eaba0eea",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num = GSDParams(512, 128)\n",
    "grid = GridEstimator.make(num)\n",
    "\n",
    "n = 40\n",
    "n = 3\n",
    "print(counts[n])\n",
    "print(jax.tree_util.tree_map(lambda x: x[n], fits))\n",
    "\n",
    "print(tfpfit(counts[n]))\n",
    "print(grid(counts[n]))\n",
    "print(gsde.fit_mle_grid(counts[n], num=num, constrain_by_pmax=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453dc67666b233ca",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# PP-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5321dba9d52b978e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T17:18:24.210177Z",
     "start_time": "2023-12-17T17:18:21.598480Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "key = jax.random.key(42)\n",
    "keys = jax.random.split(key, counts.shape[0])\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def estimator(x):\n",
    "    return grid(x)\n",
    "\n",
    "n_b=999\n",
    "\n",
    "pvals = np.stack(\n",
    "    [\n",
    "        pp_plot_data(c, estimator=estimator, key=key, n_bootstrap_samples=n_b)\n",
    "        for c, key in zip(counts, keys)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db133511b9864a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T17:18:24.308774Z",
     "start_time": "2023-12-17T17:18:24.208707Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def pp_plot(pvalues: np.ndarray, thresh_pvalue=0.2):\n",
    "\n",
    "    n_pvs = len(pvalues)\n",
    "    ref_p_values = np.linspace(start=0.001, stop=thresh_pvalue, num=100)\n",
    "    significance_line = ref_p_values + norm.ppf(0.95) * np.sqrt(\n",
    "        ref_p_values * (1 - ref_p_values) / n_pvs\n",
    "    )\n",
    "\n",
    "    def count_pvs_fraction(p_value, p_value_per_pvs):\n",
    "        return jnp.sum(p_value_per_pvs <= p_value) / len(p_value_per_pvs)\n",
    "\n",
    "    pvs_fraction_gsd = np.asarray(\n",
    "        jax.vmap(count_pvs_fraction, in_axes=(0, None))(pvalues, pvalues)\n",
    "    )\n",
    "\n",
    "    plt.scatter(pvalues, pvs_fraction_gsd, label=\"GSD\")\n",
    "\n",
    "    plt.xlabel(\"theoretical uniform cdf\")\n",
    "    plt.ylabel(\"ecdf of $p$-values\")\n",
    "    plt.plot(ref_p_values, significance_line, \"-k\")\n",
    "    plt.xlim([0, thresh_pvalue])\n",
    "    plt.ylim([0, thresh_pvalue + 0.1])\n",
    "    plt.minorticks_on()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "pp_plot(pvals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
