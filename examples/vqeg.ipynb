{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gsd-authors/gsd/blob/main/examples/vqeg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ref_gsd"
      ],
      "metadata": {
        "id": "aHomDVu97BXx"
      },
      "id": "aHomDVu97BXx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "id": "initial_id",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Imports\n",
        "from functools import partial\n",
        "\n",
        "import gsd\n",
        "import gsd.experimental as gsde\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import requests\n",
        "import tensorflow_probability.substrates.jax as tfp\n",
        "from gsd.experimental.bootstrap import pp_plot_data\n",
        "from gsd.experimental.fit import GridEstimator\n",
        "from gsd.fit import GSDParams, allowed_region, make_logits\n",
        "from jax import Array\n",
        "from jax.flatten_util import ravel_pytree\n",
        "from jax.typing import ArrayLike\n",
        "import pandas as pd\n",
        "\n",
        "tfd = tfp.distributions\n",
        "tfb = tfp.bijectors"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "title: Reference implementation of generalised score distribution in python VQEG meeting\n",
        "\n",
        "author: Krzysztof Rusek, Lucjan Janowski\n",
        "\n",
        "date: 19-12-2023\n",
        "\n",
        "# What is Generalised Score Distribution (GSD) ?\n",
        "\n",
        "- A discrete distribution supported on $\\{1,\\ldots,M\\}$ covering all possible variances\n",
        "- Parameterized by its expectation value ($\\psi$)\n",
        "- And shape parameter ($\\rho$)\n",
        "- Variance is a linear function of $\\rho$\n",
        "  -  $\\rho=1=>$ minimal variance ($[0,0,1,0,0]$, $[0.25,0.75,0,0,0]$)\n",
        "  -  $\\rho=0=>$ maximal variance ($[0.5,0,0,0,0.5]$, $[13/16, 0, 0, 0, 3/16]$)\n",
        "- *Inductive bias for subjective experiments*\n",
        "\n",
        "# `ref_gsd` package\n",
        "\n",
        "## https://github.com/gsd-authors/gsd\n",
        "\n",
        "- Probability mass function of GSD\n",
        "- Efficient `log_prob` and `sample` in JAX\n",
        "- Additional utilities (MLE, ppplot,...)\n",
        "\n",
        "For  $O\\sim\\mathcal{GSD}(\\psi,\\rho)$, we provide\n",
        "\n",
        "# PMF\n",
        "\n",
        "$$\\mathbb{P}(O=k)$$\n",
        "\n",
        "```\n",
        "gsd_prob(ψ: float, ρ: float, k: int)->float\n",
        "```\n",
        "\n",
        "__Pure Python, focused on correctness__\n",
        "\n",
        "# JAX\n",
        "\n",
        "__For efficiency__ (GPU, jit and autograd),only $M=5$\n",
        "\n",
        "- `log_prob(psi,rho,k)` ($\\log \\mathbb{P}(O=k)$)\n",
        "- `sample`\n",
        "- `mean`\n",
        "- `variance`\n",
        "- `fit*`\n",
        "- ...\n",
        "- Full API doc [https://gsd-authors.github.io/gsd/](https://gsd-authors.github.io/gsd/)\n",
        "\n",
        "# `gsd.experimental`\n",
        "\n",
        "Some useful tools that\n",
        "\n",
        "- Is not a simple function\n",
        "- or should be moved to another repo\n",
        "- or need to be polished\n",
        "\n",
        "# Demo\n",
        "\n",
        "You can use this software to:\n",
        "\n",
        "- Estimate parameters\n",
        "- Compare experiments\n",
        "- Check consistency\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "5dcb28fac32c17d"
      },
      "id": "5dcb28fac32c17d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Estimate parameters"
      ],
      "metadata": {
        "collapsed": false,
        "id": "69cef118a3a4d7b7"
      },
      "id": "69cef118a3a4d7b7"
    },
    {
      "cell_type": "markdown",
      "id": "fd7b4d0c27bc1fba",
      "metadata": {
        "collapsed": false,
        "id": "fd7b4d0c27bc1fba"
      },
      "source": [
        "Lets use one experiment form sureal library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbd38f4150b3992c",
      "metadata": {
        "id": "dbd38f4150b3992c"
      },
      "outputs": [],
      "source": [
        "url = \"https://raw.githubusercontent.com/Netflix/sureal/master/test/resource/NFLX_dataset_public_raw.py\"\n",
        "dataset = {}\n",
        "try:\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        content = response.text\n",
        "        exec(content, {}, dataset)\n",
        "    else:\n",
        "        print(f\"Failed to retrieve the file. Status code: {response.status_code}\")\n",
        "except requests.RequestException as e:\n",
        "    print(f\"Error fetching the file: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17a657c1880da152",
      "metadata": {
        "id": "17a657c1880da152"
      },
      "outputs": [],
      "source": [
        "o = np.asarray([v[\"os\"] for v in dataset[\"dis_videos\"]])\n",
        "print(o.shape)\n",
        "counts = jax.vmap(gsd.sufficient_statistic)(o)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6704abfdd927c4a",
      "metadata": {
        "id": "f6704abfdd927c4a"
      },
      "outputs": [],
      "source": [
        "@jax.jit\n",
        "def gsdfit(x: Array):\n",
        "    params, opt_state = gsde.fit_mle(data=x, max_iterations=200)\n",
        "    return params"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97f03ac8756106f5",
      "metadata": {
        "collapsed": false,
        "id": "97f03ac8756106f5"
      },
      "source": [
        "Fit model for a single PVS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd385dbacc3274db",
      "metadata": {
        "id": "dd385dbacc3274db"
      },
      "outputs": [],
      "source": [
        "gsdfit(counts[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c131353afb7ec48",
      "metadata": {
        "collapsed": false,
        "id": "2c131353afb7ec48"
      },
      "source": [
        "And compare the fit to the one estimated without a gradient:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d429f5393afe2ad3",
      "metadata": {
        "id": "d429f5393afe2ad3",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Nelder Mead from tfp\n",
        "theta0 = GSDParams(psi=2.0, rho=0.9)\n",
        "x0, unravel_fn = ravel_pytree(theta0)\n",
        "\n",
        "\n",
        "def nll(x: ArrayLike, data: Array) -> Array:\n",
        "    logits = make_logits(unravel_fn(x))\n",
        "    #tv = allowed_region(logits, data.sum())\n",
        "    ret = -jnp.dot(logits, data)\n",
        "\n",
        "    return ret\n",
        "\n",
        "\n",
        "@jax.jit\n",
        "def tfpfit(data: Array):\n",
        "    initial_simplex = np.asarray(\n",
        "        [\n",
        "            [4.9, 0.1],\n",
        "            [1.1, 0.9],\n",
        "            [4.9, 0.9],\n",
        "        ]\n",
        "    )\n",
        "    results = tfp.optimizer.nelder_mead_minimize(\n",
        "        partial(nll, data=data), initial_simplex=jnp.asarray(initial_simplex)\n",
        "    )\n",
        "    return unravel_fn(results.position)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "635036841f94975e",
      "metadata": {
        "id": "635036841f94975e"
      },
      "outputs": [],
      "source": [
        "[gsdfit(counts[0]), tfpfit(counts[0])]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4b58d36e594762c",
      "metadata": {
        "collapsed": false,
        "id": "d4b58d36e594762c"
      },
      "source": [
        "Let's estimate parameter for all the PVSs.\n",
        "For this we are going to use `jax.lax.map`.\n",
        " _Note, that `vmap` is nor best here as each estimatio contain control flow instructions._\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b53e0644aadfcb2",
      "metadata": {
        "id": "b53e0644aadfcb2"
      },
      "outputs": [],
      "source": [
        "fits = jax.lax.map(gsdfit, counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f97a3617eaba0eea",
      "metadata": {
        "id": "f97a3617eaba0eea"
      },
      "outputs": [],
      "source": [
        "num = GSDParams(512, 128)\n",
        "grid = GridEstimator.make(num)\n",
        "\n",
        "\n",
        "n = 3\n",
        "print(counts[n])\n",
        "print(jax.tree_util.tree_map(lambda x: x[n], fits))\n",
        "\n",
        "print(tfpfit(counts[n]))\n",
        "print(grid(counts[n]))\n",
        "print(gsde.fit_mle_grid(counts[n], num=num, constrain_by_pmax=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compare experiments\n",
        "\n",
        "Lets compare thsi experiment to `HDTV`"
      ],
      "metadata": {
        "collapsed": false,
        "id": "c1b10323147f6fae"
      },
      "id": "c1b10323147f6fae"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get estimates for HDTV"
      ],
      "metadata": {
        "collapsed": false,
        "id": "5b645a60de4c3d22"
      },
      "id": "5b645a60de4c3d22"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "hdtvfits = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vQ0TpGW07IrLhKkKAQvK5jsKlmghopKB5gIaY-Fd4NVBXjbyXAyffIavJxVFvMacILI8KexFLEW3dCL/pub?gid=824583765&single=true&output=csv')\n",
        "hdtvfits"
      ],
      "metadata": {
        "id": "7180af6e192f58a3"
      },
      "id": "7180af6e192f58a3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "myfits = jax.jit(jax.vmap(grid))(counts)\n",
        "myfits = jax.tree_util.tree_map(np.asarray, myfits)"
      ],
      "metadata": {
        "id": "f8cdcdef6d056dea"
      },
      "id": "f8cdcdef6d056dea"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "sns.set()\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.displot(data=hdtvfits, x='psi',y='rho', kind='kde')\n",
        "sns.scatterplot(x=myfits.psi,y=myfits.rho, color='k')\n",
        "plt.legend(['its'])\n",
        "plt.title(\"density of GSD parameters\")"
      ],
      "metadata": {
        "id": "5f47962dc3cb0ced"
      },
      "id": "5f47962dc3cb0ced"
    },
    {
      "cell_type": "markdown",
      "id": "453dc67666b233ca",
      "metadata": {
        "collapsed": false,
        "id": "453dc67666b233ca"
      },
      "source": [
        "# Check consistency\n",
        "##  PP-plot\n",
        "\n",
        "Let's apply methodology from `Nawala, Jakub, et al. \"Describing Subjective Experiment Consistency by p-Value P--P Plot.\" Proceedings of the 28th ACM International Conference on Multimedia. 2020.`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5321dba9d52b978e",
      "metadata": {
        "id": "5321dba9d52b978e"
      },
      "outputs": [],
      "source": [
        "key = jax.random.key(42)\n",
        "keys = jax.random.split(key, counts.shape[0])\n",
        "\n",
        "\n",
        "@jax.jit\n",
        "def estimator(x):\n",
        "    return grid(x)\n",
        "\n",
        "n_b=99\n",
        "\n",
        "pvals = np.stack(\n",
        "    [\n",
        "        pp_plot_data(c, estimator=estimator, key=key, n_bootstrap_samples=n_b)\n",
        "        for c, key in zip(counts, keys)\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6db133511b9864a6",
      "metadata": {
        "id": "6db133511b9864a6"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import norm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def pp_plot(pvalues: np.ndarray, thresh_pvalue=0.2):\n",
        "\n",
        "    n_pvs = len(pvalues)\n",
        "    ref_p_values = np.linspace(start=0.001, stop=thresh_pvalue, num=100)\n",
        "    significance_line = ref_p_values + norm.ppf(0.95) * np.sqrt(\n",
        "        ref_p_values * (1 - ref_p_values) / n_pvs\n",
        "    )\n",
        "\n",
        "    def count_pvs_fraction(p_value, p_value_per_pvs):\n",
        "        return jnp.sum(p_value_per_pvs <= p_value) / len(p_value_per_pvs)\n",
        "\n",
        "    pvs_fraction_gsd = np.asarray(\n",
        "        jax.vmap(count_pvs_fraction, in_axes=(0, None))(pvalues, pvalues)\n",
        "    )\n",
        "\n",
        "    plt.scatter(pvalues, pvs_fraction_gsd, label=\"GSD\")\n",
        "\n",
        "    plt.xlabel(\"theoretical uniform cdf\")\n",
        "    plt.ylabel(\"ecdf of $p$-values\")\n",
        "    plt.plot(ref_p_values, significance_line, \"-k\")\n",
        "    plt.xlim([0, thresh_pvalue])\n",
        "    plt.ylim([0, thresh_pvalue + 0.1])\n",
        "    plt.minorticks_on()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "pp_plot(pvals)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Larger experiment"
      ],
      "metadata": {
        "collapsed": false,
        "id": "961172ba3a891436"
      },
      "id": "961172ba3a891436"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "all_tidy = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vS8k8EkOW5heGWnmx7rsJjVW-PCUDsTGNOwckOkAEtGvrKaf6yk0bBFTngqCJQstdh0RLOAY1HwBf2S/pub?gid=544207226&single=true&output=csv')\n",
        "acrscores = all_tidy[all_tidy.scale==\"ACR\"].groupby(['lab','PVS'])['score'].apply(list)"
      ],
      "metadata": {
        "id": "106d646aa74dbc52"
      },
      "id": "106d646aa74dbc52"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "n_b=99\n",
        "key = jax.random.key(42)\n",
        "keys = jax.random.split(key, len(acrscores))\n",
        "\n",
        "pvals = np.stack(\n",
        "    [\n",
        "        pp_plot_data(gsd.sufficient_statistic(c), estimator=estimator, key=key, n_bootstrap_samples=n_b)\n",
        "        for c, key in zip(acrscores, keys)\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "id": "c8917f6ece7d435"
      },
      "id": "c8917f6ece7d435"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "pp_plot(pvals)"
      ],
      "metadata": {
        "id": "c71558ca6ecab9c1"
      },
      "id": "c71558ca6ecab9c1"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}