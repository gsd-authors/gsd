{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"GSD","text":"<p>Reference implementation of generalised score distribution in python</p> <p>This library provides a reference implementation of gsd probabilities for correctness and efficient implementation of samples and log_probabilities in <code>jax</code>.</p>"},{"location":"#citations","title":"Citations","text":"<p>Theoretical derivation of GSD is described in the following papers.</p> <pre><code>@Article{Cmiel2023,\nauthor={{\\'{C}}miel, Bogdan\nand Nawa{\\l}a, Jakub\nand Janowski, Lucjan\nand Rusek, Krzysztof},\ntitle={Generalised score distribution: underdispersed continuation of the beta-binomial distribution},\njournal={Statistical Papers},\nyear={2023},\nmonth={Feb},\nday={09},\nissn={1613-9798},\ndoi={10.1007/s00362-023-01398-0},\nurl={https://doi.org/10.1007/s00362-023-01398-0}\n}\n</code></pre> <pre><code>@ARTICLE{gsdnawala,\n  author={Nawa\u0142a, Jakub and Janowski, Lucjan and \u0106miel, Bogdan and Rusek, Krzysztof and P\u00e9rez, Pablo},\n  journal={IEEE Transactions on Multimedia}, \n  title={Generalized Score Distribution: A Two-Parameter Discrete Distribution Accurately Describing Responses From Quality of Experience Subjective Experiments}, \n  year={2022},\n  volume={},\n  number={},\n  pages={1-15},\n  doi={10.1109/TMM.2022.3205444}\n  }\n</code></pre> <p>If you decide to apply the concepts presented or base on the provided code, please do refer our related paper.</p>"},{"location":"#installation","title":"Installation","text":"<p>You can install gsd via <code>pip</code>:</p> <pre><code>pip install ref_gsd\n</code></pre>"},{"location":"#development","title":"Development","text":"<p>To develop and modify gsd, you need to install <code>hatch</code>, a tool for Python packaging and dependency management.</p> <p>To  enter a virtual environment for testing or debugging, you can run:</p> <pre><code>hatch shell\n</code></pre>"},{"location":"#running-tests","title":"Running tests","text":"<p>Gsd uses unitest for testing. To run the tests, use the following command:</p> <pre><code>hatch run test \n</code></pre>"},{"location":"#standalone-estimator","title":"Standalone estimator","text":"<p>You can quickly estimate GSD parameters from a command line interface</p> <pre><code>python3 -m gsd -c 1 2 3 4 5\n</code></pre> <pre><code>psi=3.6667 rho=0.6000\n</code></pre>"},{"location":"api/","title":"API","text":""},{"location":"api/#reference-implementation-in-python","title":"Reference implementation in python","text":"<p>In order to keep the reference implementation as close to the math as possible we define some utilities with unicode symbols. E.g.  <code>\ud835\udeb7(i for i in \u2124[1,3])</code> is a valid python code for </p> <p>\\(\\prod_{i=1}^{3} i\\) </p>"},{"location":"api/#gsd.gsd_prob","title":"<code>gsd.gsd_prob(\u03c8, \u03c1, k)</code>","text":"<p>Reference implementation of GSD probabilities in pure python.</p> <p>Parameters:</p> Name Type Description Default <code>\u03c8</code> <code>float</code> <p>mean</p> required <code>\u03c1</code> <code>float</code> <p>dispersion</p> required <code>k</code> <code>int</code> <p>response</p> required <p>Returns:</p> Type Description <code>float</code> <p>probability of response k</p>"},{"location":"api/#jax-functions","title":"JAX functions","text":"<p>Distribution functions implemented in JAX for speed and auto differentiation.</p> <p>Currently, we support only GSD with 5 point scale</p>"},{"location":"api/#gsd.log_prob","title":"<code>gsd.log_prob(psi, rho, k)</code>","text":"<p>Compute log probability of the response k for given parameters.</p> <p>Parameters:</p> Name Type Description Default <code>psi</code> <code>ArrayLike</code> <p>mean</p> required <code>rho</code> <code>ArrayLike</code> <p>dispersion</p> required <code>k</code> <code>ArrayLike</code> <p>response</p> required <p>Returns:</p> Type Description <code>Array</code> <p>log of the probability in GSD distribution</p>"},{"location":"api/#gsd.sample","title":"<code>gsd.sample(psi, rho, shape, key)</code>","text":"<p>Sample from GSD</p> <p>Parameters:</p> Name Type Description Default <code>psi</code> <code>ArrayLike</code> <p>mean</p> required <code>rho</code> <code>ArrayLike</code> <p>dispersion</p> required <code>shape</code> <code>Shape</code> <p>sample shape</p> required <code>key</code> <code>PRNGKeyArray</code> <p>random key</p> required <p>Returns:</p> Type Description <code>Array</code> <p>Array of shape :param shape:</p>"},{"location":"api/#gsd.mean","title":"<code>gsd.mean(psi, rho)</code>","text":"<p>Mean of GSD distribution</p>"},{"location":"api/#gsd.variance","title":"<code>gsd.variance(psi, rho)</code>","text":"<p>Variance of GSD distribution</p>"},{"location":"api/#gsd.sufficient_statistic","title":"<code>gsd.sufficient_statistic(data)</code>","text":"<p>Compute GSD sufficient statistic from samples.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ArrayLike</code> <p>Samples from GSD data[i] in [1..5]</p> required <p>Returns:</p> Type Description <code>Array</code> <p>Counts of each possible values</p>"},{"location":"api/#fit","title":"Fit","text":"<p>We provide two estimators.  The simple one based on moments and the maximum likelihood estimator.</p>"},{"location":"api/#gsd.fit_mle","title":"<code>gsd.fit_mle(data, max_iterations=100, log_lr_min=-15, log_lr_max=2.0, num_lr=10)</code>","text":"<p>Finds the maximum likelihood estimator of the GSD parameters. The algorithm used here is a simple gradient ascent. We use the concept of projected gradient to enforce constraints for parameters (psi in [1, 5], rho in [0, 1]) and exhaustive search for line search along the gradient.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ArrayLike</code> <p>An array of counts for each response.</p> required <code>max_iterations</code> <code>int</code> <p>Maximum number of iterations.</p> <code>100</code> <code>log_lr_min</code> <code>ArrayLike</code> <p>Log2 of the smallest learning rate.</p> <code>-15</code> <code>log_lr_max</code> <code>ArrayLike</code> <p>Log2 of the largest learning rate.</p> <code>2.0</code> <code>num_lr</code> <code>ArrayLike</code> <p>Number of learning rates to check during the line search.</p> <code>10</code> <p>Returns:</p> Type Description <code>tuple[GSDParams, OptState]</code> <p>An opt state whore params filed contains estimated values of GSD Parameters</p>"},{"location":"api/#gsd.fit_moments","title":"<code>gsd.fit_moments(data)</code>","text":"<p>Fits GSD using moments estimator</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ArrayLike</code> <p>An Array of counts of each response.</p> required <p>Returns:</p> Type Description <code>GSDParams</code> <p>GSD Parameters</p>"},{"location":"api/#structures","title":"Structures","text":""},{"location":"api/#gsd.fit.GSDParams","title":"<code>gsd.fit.GSDParams</code>","text":"<p>             Bases: <code>NamedTuple</code></p> <p>NamedTuple representing parameters for the Generalized Score Distribution (GSD).</p> <p>This class is used to store the psi and  rho parameters for the GSD. It provides a convenient way to group these parameters together for use in various statistical and modeling applications.</p>"},{"location":"api/#gsd.fit.OptState","title":"<code>gsd.fit.OptState</code>","text":"<p>             Bases: <code>NamedTuple</code></p> <p>A class representing the state of an optimization process.</p> <p>Attributes:</p> <p>Parameters:</p> Name Type Description Default <code>(GSDParams)</code> <code>params</code> <p>The current optimization parameters.</p> required <code>(int)</code> <code>count</code> <p>An integer count indicating the step or iteration of the optimization process.  This class is used to store and manage the state of an optimization algorithm, allowing you to keep track of the current parameters, previous parameters, and the step count.</p> required"},{"location":"examples/bayes/","title":"Bayes","text":"<pre><code>!pip install ref_gsd\n</code></pre> <pre><code>from jax import config\n\nconfig.update(\"jax_enable_x64\", True)\nimport jax\nimport jax.numpy as jnp\nimport numpy as np\nfrom scipy.integrate import dblquad\n\nfrom gsd import log_prob\n</code></pre> <pre><code>data = jnp.asarray([5, 12, 3, 0, 0])\nk = jnp.arange(1, 6)\n\n\n@jax.jit\ndef posterior(psi, rho):\n    log_posterior = jax.vmap(log_prob, in_axes=(None, None, 0))(psi, rho, k) @ data + 1. + 1 / 4.\n    posterior = jnp.exp(log_posterior)\n    return posterior\n\n\nepsabs = 1e-14\nepsreal = 1e-11\n</code></pre> <pre><code>Z, Zerr = dblquad(posterior, a=0, b=1, gfun=lambda x: 1., hfun=lambda x: 5., epsabs=epsabs, epsrel=epsreal)\npsi_hat, _ = dblquad(jax.jit(lambda psi, rho: psi * posterior(psi, rho)), a=0, b=1, gfun=lambda x: 1.,\n                      hfun=lambda x: 5.,\n                      epsabs=epsabs, epsrel=epsreal)\npsi_hat = psi_hat / Z\nrho_hat, _ = dblquad(jax.jit(lambda psi, rho: rho * posterior(psi, rho)), a=0, b=1, gfun=lambda x: 1.,\n                      hfun=lambda x: 5.,\n                      epsabs=epsabs, epsrel=epsreal)\nrho_hat = rho_hat / Z\n</code></pre> <pre><code>psi_ci, _ = dblquad(jax.jit(lambda psi, rho: (psi_hat - psi) ** 2 * posterior(psi, rho)), a=0, b=1,\n                    gfun=lambda x: 1., hfun=lambda x: 5.,\n                    epsabs=epsabs, epsrel=epsreal)\n\npsi_ci = np.sqrt(psi_ci / Z)\n\nrho_ci, _ = dblquad(jax.jit(lambda psi, rho: (rho_hat - rho) ** 2 * posterior(psi, rho)), a=0, b=1,\n                    gfun=lambda x: 1., hfun=lambda x: 5.,\n                    epsabs=epsabs, epsrel=epsreal)\n\nrho_ci = np.sqrt(rho_ci / Z)\n\nk @ data / data.sum()\n</code></pre>"},{"location":"examples/bayes/#info","title":"Info","text":"<p>This notebook shows how to estimate GSD with uncertainty.</p>"},{"location":"examples/bayes/#data-and-prior","title":"Data and prior","text":"<p>We assume no prior knowledge i.e. uniform prior for psi and rho.</p>"},{"location":"examples/bayes/#posterior","title":"Posterior","text":"<p>Normalization constant and related integrals are computed numerically.</p>"},{"location":"examples/colab/","title":"Colab","text":"<pre><code>!pip install ref_gsd\n</code></pre> <pre><code>import gsd\nprint(gsd.__version__)\n</code></pre> <pre><code>gsd.gsd_prob(4.,0.8,2)\n</code></pre> <pre><code>gsd.fit_mle([2,8,2,0,0.])\n</code></pre>"},{"location":"examples/colab/#info","title":"Info","text":"<p>This is template notebook experiments with GSD in colab.</p>"}]}